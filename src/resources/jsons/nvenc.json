{
  "Introduction": "NVIDIA® GPUs based on NVIDIA KeplerTM and later GPU architectures contain a hardware- based H.264/HEVC/AV1 video encoder (hereafter referred to as NVENC). The NVENC hardware takes YUV/RGB as input and generates an H.264/HEVC/AV1 compliant video bit stream. NVENC hardware’s encoding capabilities can be accessed using the NVENCODE APIs, available in the NVIDIA Video Codec SDK.\nThis document provides information on how to program the NVENC using the NVENCODE APIs exposed in the SDK. The NVENCODE APIs expose encoding capabilities on Windows (Windows 10 and above) and Linux.\nIt is expected that developers should understand H.264/HEVC/AV1 video codecs and be familiar with Windows and/or Linux development environments.\nNVENCODE API guarantees binary backward compatibility (and will make explicit reference whenever backward compatibility is broken). This means that applications compiled with older versions of released API will continue to work on future driver versions released by NVIDIA.",
  "Basic Encoding Flow": {"basic flow about NVENCODE API": "Developers can create a client application that calls NVENCODE API functions exposed by nvEncodeAPI.dll for Windows or libnvidia-encode.so for Linux. These libraries are installed as part of the NVIDIA display driver. The client application can either link to these libraries at run-time using LoadLibrary() on Windows or dlopen() on Linux.\nThe NVENCODE API functions, structures and other parameters are exposed in nvEncodeAPI.h, which is included in the SDK.\nNVENCODE API is a C-API, and uses a design pattern like C++ interfaces, wherein the application creates an instance of the API and retrieves a function pointer table to further interact with the encoder. For programmers preferring more high-level API with ready-to-use code, SDK includes sample C++ classes expose important API functions.\nRest of this document focuses on the C-API exposed in nvEncodeAPI.h. NVENCODE API is designed to accept raw video frames (in YUV or RGB format) and output the H.264, HEVC or AV1 bitstream.",
    " the encoding flow consists of the following steps:": [
                                                          "1. Initialize the encoder",
                                                          "2. Set up the desired encoding parameters",
                                                          "3. Allocate input/output buffers",
                                                          "4. Copy frames to input buffers and read bitstream from the output buffers. This can be done synchronously (Windows & Linux) or asynchronously (Windows 10 and above only).",
                                                          "5. Clean-up - release all allocated input/output buffers",
                                                          "6. Close the encoding session"]},
  "Setting Up Hardware for Encoding": {
    "Opening an Encode Session": {
    "Introduction": "After loading the DLL or shared object library, the client's first interaction with the API is to call NvEncodeAPICreateInstance. This populates the input/output buffer passed to NvEncodeAPICreateInstance with pointers to functions which implement the functionality provided in the interface.\nAfter loading the NVENC Interface, the client should first call NvEncOpenEncodeSessionEx to open an encoding session. This function returns an encode session handle which must be used for all subsequent calls to the API functions in the current session.",
    "Initializing encode device": {
      "The NVIDIA Encoder supports use of the following types of devices:":  {
        "DirectX 9":  "The client should create a DirectX 9 device with behavior flags including : D3DCREATE_FPU_PRESERVE, D3DCREATE_MULTITHREADED and\n‣ D3DCREATE_HARDWARE_VERTEXPROCESSING\nThe client should pass a pointer to IUnknown interface of the created device (typecasttovoid *)asNV_ENC_OPEN_ENCODE_SESSION_EX_PARAMS::device,andset NV_ENC_OPEN_ENCODE_SESSION_EX_PARAMS::deviceType to NV_ENC_DEVICE_TYPE_DIRECTX. Use of DirectX devices is supported only on Windows 10 and later versions of the Windows OS.",
        "DirectX 10":  "The client should pass a pointer to IUnknown interface of the created device (typecasttovoid *)asNV_ENC_OPEN_ENCODE_SESSION_EX_PARAMS::device,andset NV_ENC_OPEN_ENCODE_SESSION_EX_PARAMS::deviceType to NV_ENC_DEVICE_TYPE_DIRECTX. Use of DirectX devices is supported only on Windows 10 and later versions of Windows OS.",
        "DirectX 11": "The client should pass a pointer to IUnknown interface of the created device (typecasttovoid *)asNV_ENC_OPEN_ENCODE_SESSION_EX_PARAMS::device,andset NV_ENC_OPEN_ENCODE_SESSION_EX_PARAMS::deviceType to NV_ENC_DEVICE_TYPE_DIRECTX. Use of DirectX devices is supported only on Windows 10 and later versions of Windows OS.",
        "DirectX 12": "The client should pass a pointer to IUnknown interface of the created device (typecasttovoid *)asNV_ENC_OPEN_ENCODE_SESSION_EX_PARAMS::device,andset NV_ENC_OPEN_ENCODE_SESSION_EX_PARAMS::deviceType to NV_ENC_DEVICE_TYPE_DIRECTX. Use of DirectX 12 devices is supported only on Windows 10 20H1 and later versions of Windows OS.",
        "CUDA": "The client should create a floating CUDA context, and pass the CUDA context handle as NV_ENC_OPEN_ENCODE_SESSION_EX_PARAMS::device, and set NV_ENC_OPEN_ENCODE_SESSION_EX_PARAMS::deviceType to NV_ENC_DEVICE_TYPE_CUDA. Use of CUDA device for Encoding is supported on Linux and Windows 10 and later versions of Windows OS.",
        "OpenGL": "The client should create an OpenGL context and make it current (in order to associate the context with the thread/process that is making calls to NVENCODE API) to the thread calling into NVENCODE API. NV_ENC_OPEN_ENCODE_SESSION_EX_PARAMS::device must be NULL and NV_ENC_OPEN_ENCODE_SESSION_EX_PARAMS::deviceType must be set to NV_ENC_DEVICE_TYPE_OPENGL. Use of the OpenGL device type for encoding is supported only on Linux."
      }}},
    "Selecting Encoder Codec GUID": "\nThe client should select an Encoding GUID that represents the desired codec for encoding the video sequence in the following manner:\n1. TheclientshouldcallNvEncGetEncodeGUIDCounttogetthenumberofsupportedEncoder GUIDs from the NVIDIA Video Encoder Interface.\n2. The client should use this count to allocate a large-enough buffer to hold the supported Encoder GUIDS.\n3. The client should then call NvEncGetEncodeGUIDs to populate this list.\nThe client should select a GUID that matches its requirement from this list and use that as the\nencodeGUID for the remainder of the encoding session.",
    "Encoder TUNING INFO AND Preset Configurations":"The NVIDIA Encoder Interface exposes four different tuning info enums (high quality, low latency, ultra-low latency and lossless) to cater to different video encoding use-cases. Table 1 shows the recommended tuning info applicable to some popular use-cases."
}
}